


# main.py (FastAPI application)
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, Tuple, List
import time

from modules.execute_llm_select_query import execute_llm_select_query
from LLMs.generate_visualization_query import generate_visualization_query

# ======================================
# FastAPI Application
# ======================================
app = FastAPI(
    title="SmartQueryBI",
    description="""
SmartQueryBI

SmartQueryBI is an AI-powered microservice that uses LLaMA to convert natural language descriptions into secure SQL queries for Supabase. Key features include:

- Translating natural language into SQL queries.
- Executing safe SQL queries (supports SELECT, JOIN, UNION, WINDOW, GROUP BY, LIMIT, WHERE, ORDER BY, etc.) while blocking potentially harmful operations (INSERT, UPDATE, DELETE, CREATE).
- Returning query results in JSON format.
- Leveraging in-memory caching to optimize repeated queries.
- Monitoring API and cache health for reliable performance.
""",
    version="1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)


# ======================================
# Cache Configuration
# ======================================
CACHE_TTL_SECONDS = 60  # 60 seconds TTL
CACHE: Dict[str, Tuple[dict, float]] = {}

# ======================================
# Pydantic Models
# ======================================
class UserRequest(BaseModel):
    description: str = "Natural language description for database query"

class QueryResponse(BaseModel):
    sql_query: str
    raw_data: list

# ======================================
# Cache Helper Functions
# ======================================
def get_cache(key: str):
    """Return cached value if present and not expired."""
    entry = CACHE.get(key)
    if entry:
        value, expire_at = entry
        if time.time() < expire_at:
            return value
        del CACHE[key]
    return None

def set_cache(key: str, value: dict):
    """Store value in cache with TTL."""
    expire_at = time.time() + CACHE_TTL_SECONDS
    CACHE[key] = (value, expire_at)

def invalidate_cache(key: str | None = None):
    """
    Invalidate cache entries.
    - key provided → invalidate a single entry
    - key None → clear entire cache
    """
    if key:
        return CACHE.pop(key, None) is not None
    CACHE.clear()
    return True

# ======================================
# Core Pipeline
# ======================================
def run_full_pipeline(description: str) -> dict:
    """
    Execute the full LLM → SQL → Data pipeline.
    Returns raw data from Supabase.
    """
    llm_result = generate_visualization_query(description)
    sql_query = llm_result["sql"].strip().rstrip(";")
    
    # Execute the query and get raw data
    execution_result = execute_llm_select_query(sql_query)
    
    if "error" in execution_result:
        return {
            "sql_query": sql_query,
            "raw_data": [],
            "error": execution_result["error"]
        }
    
    return {
        "sql_query": sql_query,
        "raw_data": execution_result.get("results", [])
    }

# ======================================
# API Endpoints
# ======================================
@app.get("/", summary="Root / Health Indicator", tags=["System"])
def read_root():
    """Returns basic service status"""
    return {"status": "ok", "service": "SmartQueryBI"}

@app.get("/health", summary="Health Check", tags=["System"])
def health_check():
    """Returns health info including cache status"""
    return {
        "status": "healthy",
        "cache_entries": len(CACHE),
        "cache_ttl_seconds": CACHE_TTL_SECONDS
    }

@app.post(
    "/dynamic-query/server-cache",
    response_model=QueryResponse,
    summary="Execute LLM-powered query with caching",
    tags=["Query Pipeline"]
)
def dynamic_query_server_cache(request: UserRequest):
    """
    Executes the full LLM → SQL → Data pipeline.

    - Checks the in-memory cache for repeated requests
    - Cache TTL is 60 seconds
    - Returns raw data from Supabase in JSON format
    """
    cached_response = get_cache(request.description)
    if cached_response:
        return cached_response

    result = run_full_pipeline(request.description)
    set_cache(request.description, result)
    return result

@app.post("/cache/invalidate", summary="Invalidate Entire Cache", tags=["Cache"])
def invalidate_entire_cache():
    """Clears all cached entries"""
    invalidate_cache()
    return {"cache_cleared": True}

@app.post(
    "/cache/invalidate/{description}",
    summary="Invalidate Cache for Specific Request",
    tags=["Cache"]
)
def invalidate_single_cache(description: str):
    """Deletes cache entry for a specific user description"""
    removed = invalidate_cache(description)
    if not removed:
        raise HTTPException(status_code=404, detail="Cache entry not found")
    return {"invalidated": True}

# ======================================
# Lifecycle Events
# ======================================
@app.on_event("startup")
def on_startup():
    print("SmartQueryBI started. In-memory cache initialized.")

@app.on_event("shutdown")
def on_shutdown():
    print("SmartQueryBI shutting down. Cache cleared.")
    CACHE.clear()